{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e867a467",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf67d81",
   "metadata": {},
   "source": [
    "# 0: Downloading the Schiebinger Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3070d181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Schiebinger Dataset Downloader ---\n",
      "Directory Data/Schiebinger already exists and is not empty.\n",
      "Continuing: will attempt to extract/unpack any archives found in this directory.\n",
      "Skipping cleanup as no new download was performed.\n",
      "---\n",
      "Dataset is located in: Data/Schiebinger\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "./SchiebingerDownload.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3fba69",
   "metadata": {},
   "source": [
    "# 1: Extracting HVGs of chosen Branch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f48547b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = \"Data/Schiebinger\"\n",
    "output_directory = \"Pipeline/HVGs\"\n",
    "trunk = \"2i\"  # Options: \"serum\", \"2i\", \"both\"\n",
    "num_highly_variable_genes = 2000\n",
    "\n",
    "# Define the specific output filename\n",
    "tensor_filename = f\"schiebinger_hvg_tensor_trunk-{trunk}_{num_highly_variable_genes}hvg.pt\"\n",
    "tensor_path = os.path.join(output_directory, tensor_filename)\n",
    "\n",
    "reextract = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26c36f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File schiebinger_hvg_tensor_trunk-2i_2000hvg.pt already exists. Skipping HVG extraction.\n"
     ]
    }
   ],
   "source": [
    "from Pipeline.firstSelectHVGs import run_hvg_extraction\n",
    "\n",
    "if os.path.exists(tensor_path) and not reextract:\n",
    "    print(f\"File {tensor_filename} already exists. Skipping HVG extraction.\")\n",
    "else:\n",
    "    print(f\"Starting HVG extraction...\")\n",
    "    # --- 3. Call the function directly with your parameters ---\n",
    "    # This is clean, robust, and doesn't involve any argparse messiness.\n",
    "    hvg_fig = run_hvg_extraction(\n",
    "        data_dir=data_directory,\n",
    "        output_dir=output_directory,\n",
    "        output_file=tensor_filename,\n",
    "        trunk=trunk,\n",
    "        n_hvg=num_highly_variable_genes,\n",
    "        min_counts=2000,  \n",
    "        max_counts=50000,\n",
    "        min_cells=50,\n",
    "        debug=True\n",
    "    )\n",
    "\n",
    "    if hvg_fig:\n",
    "        print(\"\\nDisplaying diagnostic plot:\")\n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9291c013",
   "metadata": {},
   "source": [
    "# 2: Training the Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91baf53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = f\"Models/Autoencoder/trunk-{trunk}.pt\"\n",
    "latent_save_path = f\"LatentSpace/trunk-{trunk}_latent.pt\"\n",
    "\n",
    "bottleneck = 24\n",
    "\n",
    "latent_dims = [660, 220 , 66, bottleneck]\n",
    "\n",
    "batch_size = 64\n",
    "overdispersion = 0.3\n",
    "\n",
    "num_epochs = 30\n",
    "Training = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb9a821b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model already exists at Models/Autoencoder/trunk-2i.pt. Skipping training.\n"
     ]
    }
   ],
   "source": [
    "from Pipeline.secondTrainAutoencoder import run_autoencoder_training\n",
    "\n",
    "if os.path.exists(model_save_path) and not Training:\n",
    "    print(f\"Model already exists at {model_save_path}. Skipping training.\")\n",
    "else:\n",
    "    # Call the training function directly with clear, explicit parameters.\n",
    "    # This is robust, readable, and provides full IDE support.\n",
    "    run_autoencoder_training(\n",
    "        tensor_file=tensor_path,\n",
    "        model_save_path=model_save_path,\n",
    "        latent_save_path=latent_save_path,\n",
    "        latent_dims=latent_dims,\n",
    "        num_epochs=num_epochs,\n",
    "        batch_size=batch_size,\n",
    "        overdispersion=overdispersion,\n",
    "        lr=5e-4,      \n",
    "        val_split=0.2, \n",
    "        debug=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3770bc66",
   "metadata": {},
   "source": [
    "## 2.1: Visualizing the Latent Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22df9c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuML found. Using GPU for UMAP acceleration.\n",
      "Loaded 172756 latent vectors.\n",
      "--- Starting 3D Visualization ---\n",
      "Fitting UMAP model...\n",
      "Creating k3d plot...\n",
      "Coloring by continuous timepoints and adding a color bar.\n",
      "--- Visualization Complete ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9784d026e6784e0a9d9c5e18cd7206b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Plot(antialias=3, axes=['x', 'y', 'z'], axes_helper=1.0, axes_helper_colors=[16711680, 65280, 255], backgroundâ€¦"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Genodesic.Visualizers import UMAP3D\n",
    "\n",
    "latent_data_bundle = torch.load(latent_save_path)\n",
    "\n",
    "# Extract the numpy arrays for plotting\n",
    "latent_reps = latent_data_bundle['latent_reps'].numpy()\n",
    "timepoints = latent_data_bundle['timepoints'].numpy().flatten()\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Loaded {latent_reps.shape[0]} latent vectors.\")\n",
    "\n",
    "# --- 3. Call your visualization function ---\n",
    "UMAP3D(\n",
    "    latent_reps=latent_reps,\n",
    "    color_by_timepoints=timepoints,\n",
    "    title=f\"Latent Space UMAP (Trunk: {trunk})\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db4b9b5",
   "metadata": {},
   "source": [
    "# 3: Setting up Density Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afa8d040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Loading default configuration from Config/models.yaml\n",
      "INFO: Merging notebook overrides into config.\n",
      "--- Running Training for RQNSF ---\n",
      "INFO: Setting up dataloaders...\n",
      "INFO: Initializing model...\n",
      "INFO: Starting training loop...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'SequenceINN' object has no attribute 'dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mScripts\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtrain\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m run_training\n\u001b[32m      3\u001b[39m notebook_overrides = {\n\u001b[32m      4\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmodel_type\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mrqnsf\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;66;03m# Options: \"vpsde\", \"otcfm\", \"rqnsf\"\u001b[39;00m\n\u001b[32m      5\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mdata_file\u001b[39m\u001b[33m\"\u001b[39m: latent_save_path, \n\u001b[32m   (...)\u001b[39m\u001b[32m      9\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mbatch_size\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m64\u001b[39m\n\u001b[32m     10\u001b[39m }\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m trained_model = \u001b[43mrun_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig_overrides\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnotebook_overrides\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Genodesic/Scripts/train.py:88\u001b[39m, in \u001b[36mrun_training\u001b[39m\u001b[34m(config_overrides, default_config_path)\u001b[39m\n\u001b[32m     82\u001b[39m     train_loss, val_loss = train_vpsde_epoch(\n\u001b[32m     83\u001b[39m         model, train_loader, val_loader, optimizer, device,\n\u001b[32m     84\u001b[39m         beta_min=model_specific_params[\u001b[33m\"\u001b[39m\u001b[33mbeta_min\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     85\u001b[39m         beta_max=model_specific_params[\u001b[33m\"\u001b[39m\u001b[33mbeta_max\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     86\u001b[39m     )\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m model_type == \u001b[33m\"\u001b[39m\u001b[33mrqnsf\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m     train_loss, val_loss = \u001b[43mtrain_rqnsf_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     89\u001b[39m scheduler.step(val_loss)\n\u001b[32m     90\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch+\u001b[32m1\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m02d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig[\u001b[33m'\u001b[39m\u001b[33mnum_epochs\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | Train Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | Val Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Genodesic/Genodesic/DensityModels/trainer.py:63\u001b[39m, in \u001b[36mtrain_rqnsf_epoch\u001b[39m\u001b[34m(model, train_loader, val_loader, optimizer, device)\u001b[39m\n\u001b[32m     60\u001b[39m optimizer.zero_grad()\n\u001b[32m     62\u001b[39m z, log_jac = model(x1)\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m log_p_z = -\u001b[32m0.5\u001b[39m * (z**\u001b[32m2\u001b[39m).sum(dim=\u001b[32m1\u001b[39m) - \u001b[32m0.5\u001b[39m * \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdim\u001b[49m * np.log(\u001b[32m2.0\u001b[39m * np.pi)\n\u001b[32m     64\u001b[39m loss = -(log_p_z + log_jac).mean()\n\u001b[32m     66\u001b[39m loss.backward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/envs/genodesic/lib/python3.11/site-packages/torch/nn/modules/module.py:1940\u001b[39m, in \u001b[36mModule.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   1938\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[32m   1939\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[32m-> \u001b[39m\u001b[32m1940\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[32m   1941\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m object has no attribute \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1942\u001b[39m )\n",
      "\u001b[31mAttributeError\u001b[39m: 'SequenceINN' object has no attribute 'dim'"
     ]
    }
   ],
   "source": [
    "from Scripts.train import run_training\n",
    "\n",
    "notebook_overrides = {\n",
    "    \"model_type\": \"rqnsf\", # Options: \"vpsde\", \"otcfm\", \"rqnsf\"\n",
    "    \"data_file\": latent_save_path, \n",
    "    \"model_save_path\": \"Models/DensityModels/rqnsf.pt\",\n",
    "    \"dim\": bottleneck,\n",
    "    \"num_epochs\": 50,\n",
    "    \"batch_size\": 64\n",
    "}\n",
    "\n",
    "trained_model = run_training(config_overrides=notebook_overrides)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "My SIF Kernel",
   "language": "python",
   "name": "sif_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
