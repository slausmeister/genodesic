{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65a7094b",
   "metadata": {},
   "source": [
    "# Genodesic Tutorial on the Schiebinger Dataset\n",
    "\n",
    "This notebook demonstrates the end-to-end **Genodesic** pipeline for trajectory reconstruction. Our goal is to find a biologically meaningful path between two cell states in the Schiebinger dataset. We achieve this by computing a geodesic with respect to a data-density-aware Fermat metric, which ensures the path realistically follows the underlying data manifold.\n",
    "\n",
    "The analysis is broken down into four key stages:\n",
    "\n",
    "1.  **Data Preparation:** We begin by downloading the dataset, selecting the most informative Highly Variable Genes (HVGs), and training an autoencoder to project the high-dimensional count data into a more manageable latent space. This creates the space where our analysis will take place.\n",
    "\n",
    "2.  **Score-Based Density Modeling:** We then train the core of our method, a VP-SDE model, on this latent space. This model learns the data's score field ($s = \\nabla_x \\log p$), which is the essential gradient information used to guide the pathfinding process.\n",
    "\n",
    "3.  **Geodesic Computation:** With the score model in hand, we select start and end cells from different timepoints. We find an initial path proposal using a density-aware graph search and then iteratively refine this guess into a smooth geodesic using our learned score function.\n",
    "\n",
    "4.  **Analysis & Validation:** Finally, we evaluate the properties of our initial and refined paths. We will analyze their length and density profiles and, most importantly, compare their progression against the dataset's known \"wall-clock time\" to validate the biological plausibility of our reconstructed trajectory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8e0e7b",
   "metadata": {},
   "source": [
    "## Global Notebook Configuration\n",
    "\n",
    "This section contains all the key parameters for the entire pipeline. It's the main control panel for this notebook.\n",
    "\n",
    "**Default Parameters & Overrides:**\n",
    "The Genodesic package uses YAML files (`Config/models.yaml` and `Config/refinement.yaml`) to store default hyperparameters for training and path refinement. Below, we define Python dictionaries that override these defaults for specific experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89566864",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mFATAL:   container creation failed: image driver mount failure: image driver squashfuse_ll instance exited with error: squashfuse_ll exited: Something went wrong trying to read the squashfs image. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "# --- A. Global Toggles & Setup ---\n",
    "ReextractHVGs = False\n",
    "RetrainAutoencoder = False\n",
    "RetrainDensity = False\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# --- B. Define Core Parameters ---\n",
    "TRUNK = \"both\"\n",
    "N_HVG = 2000\n",
    "BOTTLENECK_DIM = 24\n",
    "MODEL_TYPE = \"vpsde\"  # Options: \"vpsde\", \"otcfm\", \"rqnsf\"\n",
    "\n",
    "# --- C. Dynamically Generate All File Paths ---\n",
    "hvg_output_file = f\"schiebinger_hvg_tensor_trunk-{TRUNK}_{N_HVG}hvg.pt\"\n",
    "hvg_tensor_path = os.path.join(\"Pipeline/HVGs\", hvg_output_file)\n",
    "\n",
    "ae_model_save_path = f\"Models/Autoencoder/trunk-{TRUNK}_dim-{BOTTLENECK_DIM}_hvg-{N_HVG}.pt\"\n",
    "latent_save_path = f\"LatentSpace/trunk-{TRUNK}_dim-{BOTTLENECK_DIM}_hvg-{N_HVG}_latent.pt\"\n",
    "density_model_save_path = f\"Models/DensityModels/{MODEL_TYPE}_trunk-{TRUNK}_dim-{BOTTLENECK_DIM}.pt\"\n",
    "\n",
    "# --- D. Define All Overrides \n",
    "notebook_overrides = {\n",
    "    \"hvg_extraction\": {\n",
    "        \"output_file\": hvg_output_file,\n",
    "        \"trunk\": TRUNK,\n",
    "        \"n_hvg\": N_HVG,\n",
    "        \"min_counts\": 2000,\n",
    "        \"max_counts\": 50000,\n",
    "        \"min_cells\": 50,\n",
    "    },\n",
    "    \"autoencoder\": {\n",
    "        \"model_save_path\": ae_model_save_path,\n",
    "        \"latent_save_path\": latent_save_path,\n",
    "        \"bottleneck_dim\": BOTTLENECK_DIM,\n",
    "        \"num_epochs\": 50,\n",
    "        \"learning_rate\": 0.0005,\n",
    "    },\n",
    "\n",
    "    \"density_model\": {\n",
    "        \"model_type\": MODEL_TYPE,\n",
    "        \"data_file\": latent_save_path,\n",
    "        \"model_save_path\": density_model_save_path,\n",
    "        \"dim\": BOTTLENECK_DIM,\n",
    "        \"num_epochs\": 10,\n",
    "        \"batch_size\": 512,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf67d81",
   "metadata": {},
   "source": [
    "# 0: Downloading the Schiebinger Dataset\n",
    "\n",
    "We first download and extract the Schiebinger Dataset. As this can be a bit tricky, we provide a shell script that automatically downloads the entire dataset and extracts it to Data/Schiebinger. If a dataset is already found at that path, the download is skipped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3070d181",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "Pipeline/SchiebingerDownload.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3fba69",
   "metadata": {},
   "source": [
    "# 1: Extracting HVGs of chosen Branch\n",
    "\n",
    "We now combine all datasets and filter for the desired branch. Afterwards we run HVG extraction and save the new combined HVG count matrix to disk. Per default the extraction is skipped if the count matrix already exists. The boolean `ReextractHVGs` overwrites this check. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26c36f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Genodesic.Utils import load_config\n",
    "from Pipeline.firstSelectHVGs import run_hvg_extraction\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if os.path.exists(hvg_tensor_path) and not ReextractHVGs:\n",
    "    print(f\"File {hvg_output_file} already exists. Skipping.\")\n",
    "else:\n",
    "    print(\"Starting HVG extraction...\")\n",
    "    hvg_config = load_config(\n",
    "        default_config_path='Config/hvg_extraction.yaml',\n",
    "        overrides=notebook_overrides\n",
    "    )\n",
    "    hvg_fig = run_hvg_extraction(\n",
    "        config=hvg_config,\n",
    "        data_dir=\"Data/Schiebinger\",\n",
    "        debug=True\n",
    "    )\n",
    "    if hvg_fig: plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9291c013",
   "metadata": {},
   "source": [
    "# 2: Training the Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91baf53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Pipeline.secondTrainAutoencoder import run_autoencoder_training\n",
    "\n",
    "if os.path.exists(ae_model_save_path) and not RetrainAutoencoder:\n",
    "    print(f\"Model already exists at {ae_model_save_path}. Skipping training.\")\n",
    "else:\n",
    "    print(\"Starting autoencoder training...\")\n",
    "    ae_config = load_config(\n",
    "        default_config_path='Config/autoencoder.yaml',\n",
    "        overrides=notebook_overrides\n",
    "    )\n",
    "    run_autoencoder_training(\n",
    "        hvg_tensor_file=hvg_tensor_path,\n",
    "        config=ae_config,\n",
    "        debug=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3770bc66",
   "metadata": {},
   "source": [
    "## 2.1: Visualizing the Latent Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22df9c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Genodesic.Visualizers import UMAP3D\n",
    "\n",
    "latent_data_bundle = torch.load(latent_save_path)\n",
    "latent_reps = latent_data_bundle['latent_reps'].numpy()\n",
    "timepoints = latent_data_bundle['timepoints'].numpy().flatten()\n",
    "\n",
    "print(f\"Loaded {latent_reps.shape[0]} latent vectors.\")\n",
    "\n",
    "UMAP3D(\n",
    "    latent_reps=latent_reps,\n",
    "    color_by_timepoints=timepoints,\n",
    "    title=f\"Latent Space UMAP (Trunk: {TRUNK})\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db4b9b5",
   "metadata": {},
   "source": [
    "# 3: Setting up Density Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa8d040",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Pipeline.train import run_training\n",
    "from Genodesic.Utils import load_density_model_from_checkpoint\n",
    "\n",
    "if os.path.exists(density_model_save_path) and not RetrainDensity:\n",
    "    model = load_density_model_from_checkpoint(density_model_save_path, device=DEVICE)\n",
    "else:\n",
    "    print(\"Starting density model training...\")\n",
    "    density_config = load_config(\n",
    "        default_config_path='Config/DensityModels.yaml',\n",
    "        overrides=notebook_overrides.get(\"density_model\", {})\n",
    "    )\n",
    "    model = run_training(config=density_config)\n",
    "\n",
    "print(f\"\\nSuccessfully loaded model: {model.__class__.__name__}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09672ca6",
   "metadata": {},
   "source": [
    "#4: Trajetories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925232f6",
   "metadata": {},
   "source": [
    "## Initialization of Path\n",
    "\n",
    "First we choose the start and end time and then sample two random cells from the subsamples that are to be connected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6b59c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "start_time = 3\n",
    "end_time = 15\n",
    "\n",
    "# Find indices for each timepoint\n",
    "start_idx = np.random.choice(np.where(timepoints == start_time)[0])\n",
    "end_idx = np.random.choice(np.where(timepoints == end_time)[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da548552",
   "metadata": {},
   "source": [
    "We now initialize a path between the two sampled cells by performing a Dijkstra on the knn graph of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17af9cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Genodesic.PathTools import find_dijkstra_path\n",
    "\n",
    "init_path = find_dijkstra_path(start_idx, end_idx, latent_reps)\n",
    "UMAP3D(\n",
    "    paths=[init_path],\n",
    "    latent_reps=latent_reps,\n",
    "    color_by_timepoints=timepoints\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5bc53d",
   "metadata": {},
   "source": [
    "## Refinement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413660fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Genodesic.PathTools import run_refinement_loop\n",
    "\n",
    "refined_path = run_refinement_loop(\n",
    "    phi_initial=init_path,\n",
    "    model=model\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e842066c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from Genodesic.PathTools import DensityBasedResampling\n",
    "# \n",
    "# resampled_path = DensityBasedResampling(\n",
    "#     phi=torch.from_numpy(init_path),\n",
    "#     model=model,\n",
    "#     num_points=100,\n",
    "#     beta = -1/4\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22b63ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Genodesic.Visualizers import UMAP3D\n",
    "\n",
    "UMAP3D(\n",
    "    paths=[init_path, refined_path],\n",
    "    latent_reps=latent_reps,\n",
    "    color_by_timepoints=timepoints\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96eebd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# phi_initial = torch.from_numpy(init_path)\n",
    "# phi_relaxed = resampled_path\n",
    "# \n",
    "# # Save the path tensors to disk\n",
    "# torch.save({\n",
    "#     'phi_initial': phi_initial,\n",
    "#     'phi_relaxed': phi_relaxed\n",
    "# }, 'Genodesic_tutorial_paths.pt')\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47682bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from Genodesic.PathTools import calculate_path_statistics\n",
    "# \n",
    "# paths_to_analyze = {\n",
    "#     'Initial Path': phi_initial,\n",
    "#     'Relaxed Path': phi_relaxed\n",
    "# }\n",
    "# \n",
    "# path_statistics = calculate_path_statistics(\n",
    "#     paths_dict=paths_to_analyze,\n",
    "#     model=model,\n",
    "#     beta_param=-1/4,\n",
    "#     integration_steps=2\n",
    "# )\n",
    "# \n",
    "# from Genodesic.PathTools import report_path_statistics\n",
    "# report_path_statistics(\n",
    "#     stats_dict=path_statistics,\n",
    "#     reference_path_name='Initial Path',\n",
    "#     beta_param=-1/4,  \n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58146a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from Genodesic.PathTools import DensityBasedResampling\n",
    "# \n",
    "# resampled_path = DensityBasedResampling(\n",
    "#     phi=phi_initial,\n",
    "#     model=model,\n",
    "#     num_points=150,\n",
    "#     beta = 4\n",
    "# )\n",
    "# \n",
    "# test_path = DensityBasedResampling(\n",
    "#     phi=phi_initial,\n",
    "#     model=model,\n",
    "#     num_points=100,\n",
    "#     beta = -4\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf1f281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from Genodesic.PathTools.Wallclock import compute_path_pseudotime\n",
    "# \n",
    "# avg_initial, std_initial = compute_path_pseudotime(\n",
    "#     phi_initial, latent_reps, timepoints, k=10\n",
    "# )\n",
    "# \n",
    "# # avg_relaxed, std_relaxed = compute_path_pseudotime(\n",
    "# #     refined_path, latent_reps, timepoints, k=10\n",
    "# # )\n",
    "# \n",
    "# avg_relaxed, std_relaxed = compute_path_pseudotime(\n",
    "#     test_path, latent_reps, timepoints, k=10\n",
    "# )\n",
    "# \n",
    "# avg_resampled, std_resampled = compute_path_pseudotime(\n",
    "#     resampled_path, latent_reps, timepoints, k=10\n",
    "# )\n",
    "# \n",
    "# # 2. Collect all results into a single list of tuples\n",
    "# all_results = [\n",
    "#     (avg_initial, std_initial, 'Initial Path'),\n",
    "#     (avg_relaxed, std_relaxed, 'Test Path'),\n",
    "#     (avg_resampled, std_resampled, 'Resampled Path')\n",
    "# ]\n",
    "# \n",
    "# from Genodesic.PathTools.Diagnostics import plot_pseudotime_progressions\n",
    "# \n",
    "# # 3. Call the modified plotting function once with all the data\n",
    "# plot_pseudotime_progressions(\n",
    "#     all_results, \n",
    "#     colors=['blue', 'green', 'red']\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f11852",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from Genodesic.Visualizers import (\n",
    "    load_autoencoder_and_metadata,\n",
    "    decode_latent_trajectory,\n",
    "    find_dynamic_genes,\n",
    "    plot_dynamic_genes_heatmap\n",
    ")\n",
    "\n",
    "# --- 1. Load Model and Gene Metadata ---\n",
    "try:\n",
    "    autoencoder_model, hvg_gene_names = load_autoencoder_and_metadata(\n",
    "        ae_checkpoint_path=ae_model_save_path,\n",
    "        hvg_tensor_path=hvg_tensor_path,\n",
    "        device=DEVICE\n",
    "    )\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"ERROR: A required file was not found. Please ensure previous steps have run successfully. Details: {e}\")\n",
    "    raise\n",
    "\n",
    "# --- 2. Decode Latent Path to Gene Expression ---\n",
    "print(\"\\n--- Decoding Latent Trajectory ---\")\n",
    "expression_curve = decode_latent_trajectory(\n",
    "    autoencoder_model=autoencoder_model,\n",
    "    latent_path=refined_path, # Assuming phi_relaxed is available from a previous cell\n",
    "    device=DEVICE\n",
    ")\n",
    "print(f\"Decoded path to an expression curve of shape {expression_curve.shape}\")\n",
    "\n",
    "# --- 3. Find and Order Dynamic Genes ---\n",
    "print(\"\\n--- Identifying Dynamic Genes ---\")\n",
    "ordered_expression_data, ordered_gene_names = find_dynamic_genes(\n",
    "    expression_curve=expression_curve,\n",
    "    gene_names=hvg_gene_names,\n",
    "    num_genes=200 \n",
    ")\n",
    "\n",
    "# --- 4. Plot Heatmap ---\n",
    "print(\"\\n--- Plotting Heatmap ---\")\n",
    "plot_dynamic_genes_heatmap(\n",
    "    expression_data=ordered_expression_data,\n",
    "    gene_names=ordered_gene_names,\n",
    "    figsize=(10, 22)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Genodesic Kernel",
   "language": "python",
   "name": "apptainer-genodesic"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
